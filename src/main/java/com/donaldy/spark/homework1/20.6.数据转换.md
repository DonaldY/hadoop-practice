## 一、需求


`A` 表有三个字段: `ID`、`startdate`、`enddate`，有3条数据:
```
1 2019-03-04 2020-02-03
2 2020-04-05 2020-08-04
3 2019-10-09 2020-06-11
```

写 `SQL` (需要 `SQL` 和 `DSL` )将以上数据变化为:
```
2019-03-04  2019-10-09
2019-10-09  2020-02-03
2020-02-03  2020-04-05
2020-04-05  2020-06-11
2020-06-11  2020-08-04
2020-08-04  2020-08-04
```



## 二、实现

```scala
package com.lagou.spark.anwser

import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.{Row, SparkSession}

object HomeWork6_SparkSQL {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession
      .builder()
      .appName("Demo1")
      .master("local[*]")
      .getOrCreate()
    val sc = spark.sparkContext
    sc.setLogLevel("warn")

    import org.apache.spark.sql.functions._
    import spark.implicits._
    val df = List("1 2019-03-04 2020-02-03", "2 2020-04-05 2020-08-04", "3 2019-10-09 2020-06-11").toDF()
    
    // DSL方式
    val w1 = Window.orderBy($"value" asc).rowsBetween(0, 1)
    df.as[String]
      .map(str => str.split(" ")(1) + " " + str.split(" ")(2))
      .flatMap(str => str.split("\\s+"))
      .distinct()
      .sort($"value" asc)
      .withColumn("new", max("value") over (w1))
      .show()

    // SQL方式
    df.flatMap{ case Row(line: String) =>
      line.split("\\s+").tail
    }.toDF("date")
      .createOrReplaceTempView("t1")

    spark.sql("select date from t1").show
    spark.sql(
      """
        |select date, max(date) over (order by date rows between current row and 1 following) as date1
        |  from t1
        |""".stripMargin).show

    spark.close()
  }
}
```
